%\vspace{-0.1in}
\section{Introduction}\label{sec:intro}

Driven by the need for ultra-low latency, high throughput and low CPU overhead, both Microsoft and Google are deploying Remote Direct Memory Access (RDMA) in their datacenter networks in recent years~\cite{dcqcn,timely}. Among the available RDMA technologies,  RDMA over Converged Ethernet (RoCE)~\cite{roce} is a promising one as it is compatible with current IP and Ethernet based datacenter networks.

The deployment of RoCE requires Priority-based Flow Control (PFC)~\cite{pfc} to provide a lossless L2 network. With PFC, packet loss can be avoided by letting a switch pause its immediate upstream device before buffer overflow occurs. However, the adoption of PFC will cause deadlock problem. Deadlock refers to such a standstill situation: There is a cyclic buffer dependency among a set of switches. Any switch in the cycle holds all the buffer needed by its upstream switch, and meanwhile is waiting for its downstream switch to release some buffer and resume its packet transmission.

It is easy to see that when deadlock occurs, no switch in the cycle can proceed. Further, throughput of the whole network or part of the network will go to zero due to the backpressure effect of PFC pause. Hence it is necessary to design some mechanisms for handling deadlock problem when deploying RDMA in datacenter networks. 

Prior works on preventing deadlock can be roughly classified into two categories including 1) \textit{Routing restriction based approach}~\cite{tcpbolt,flich2012survey}. The idea of this approach is to ensure that no cyclic buffer dependency exists in the network by limiting the routing paths used in each priority class;  2) \textit{buffer management (structured buffer pool) based approach}~\cite{gerla1980flow,karol2003prevention}. This approach divides switch buffer into several buffer classes. A packet is allowed to access more buffer classes as it travels greater distance in the network. It can be proved that as long as the number of buffer classes is no smaller than the hop count of the longest routing path, there will be no cyclic buffer dependency in the network.


These two kinds of approaches are known to have some important drawbacks. For example, routing restriction based approach usually wastes link bandwidth and limits throughput performance, while buffer management based approach introduces non-trivial deployment complexity to the network system. The drawbacks of these approaches somehow can be viewed as the cost to eliminate cyclic buffer dependency in the network, which has been identified as the primary principle for designing a deadlock prevention solution.

Though obeying this principle can guarantee a deadlock-free network, its cost can be very expensive. In this paper, instead of seeking a solution that introduces less overhead, we take one step back and ask: Is cyclic buffer dependency a sufficient and necessary condition for deadlock? Or can deadlock-free be guaranteed without eliminating cyclic buffer dependency?

To answer the above questions, we did some study about several representative deadlock cases. Our findings are as follows. First, cyclic buffer dependency is just a necessary condition for deadlock. There are some cases where cyclic buffer dependency is met, but there is no deadlock. Second, even if all the links in a switch cycle are paused simultaneously, deadlock may still not occur. These two findings indicate that prior solutions are designed based on a too strict condition, and thus introduces some unnecessary overhead. 
\todo{(We need a much better discussion here, let's discuss how to argue that our deadlock case study is important and meaningful.)}


%1)\textit{Routing restriction based approach}. The idea is to limit the routing paths used in a network to ensure that there is no cyclic buffer dependency; 2)\textit{Priority class based approach.} This approach splits each physical link into several priority classes, and associates each class with some dedicated buffer at each hop. Within each priority class, only deadlock-free routes are allowed to be installed, so there will be no deadlock. 3)\textit{buffer management (structured buffer pool) based approach}. This approach divides switch buffer into several buffer classes. A packet is allowed to access more buffer classes as it travels greater distance in the network. It has been proved that as long as the number of buffer classes is no smaller than the hop count of the longest routing path in the network, there will be no deadlock. 