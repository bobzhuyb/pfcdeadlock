\section{Background}
\label{sec:background}
\para {RDMA and RoCE:} Remote Direct Memory Access (RDMA) technology offers high
throughput, low latency and low CPU overhead, by bypassing end-host networking
stacks. Instead, Network Interface Cards(NICS) transfer data in and out of
pre-registered memory buffers at the two end hosts.  In modern data centers,
RDMA is deployed using RDMA over Converged Ethernet V2 (RoCE)
standard~\cite{roce,rroce}

\para {PFC:} RoCE needs a lossless fabric for optimal performance. This is
accomplished in Ethernet networks using the Priority Flow Control (PFC)
mechanism~\cite{pfc}.  Using PFC, a switch can pause an incoming link when its
ingress buffer occupancy reaches a preset threshold. As long as sufficient
``headroom'' is reserved to buffer packets that are in flight during the time
takes for the PAUSE to take effect, no packet will be dropped due to buffer
overflow~\cite{cisco-whitepaper,dcqcn}.

The PFC standard defines 8 classes, called priorities\footnote{The word priority
is a misnomer. There is no implicit ordering among priorities -- they are really
just separate classes.}. Packets in each priority are buffered separately.
PAUSE messages carry this priority.  When a packet arrives at port $i$ of switch
$S$ with priority $j$, it is enqueued in the ingress queue $j$ of port $i$. If the ingress queue
length exceeds the PFC threshold, a pause message is sent to the upstream
switch connected to port $i$. The message carries priority $j$. The upstream
switch then stops sending packets with priority $j$ to switch $S$ on port $i$
until a resume message with priority $j$ is received.

\para{Deadlock:} PFC can lead to deadlocks when paused queues form a cycle.
Circular Buffer Dependency (CBD) is a necessary condition for
deadlock formation, and thus, deadlock avoidance schemes focus on
avoiding CBD.  We now describe the three key challenges that any
practical deadlock avoidance scheme must meet.
