\section{Background}
\label{sec:background}
\para {RDMA and RoCE:} Remote Direct Memory Access (RDMA) technology offers high
throughput, low latency and low CPU overhead, by bypassing end-host networking
stacks. Instead, Network Interface Cards(NICS) transfer data in and out of
pre-registered memory buffers at the two end hosts.  In modern data centers,
RDMA is deployed using RDMA over Converged Ethernet V2 (RoCE)
standard~\cite{roce,rroce}

\para {PFC:} RoCE needs a lossless L2 layer for optimal performance. This is
accomplished in Ethernet networks using the Priority Flow Control (PFC)
mechanism~\cite{pfc}.  Using PFC, a switch can pause an incoming link when its
ingress buffer occupancy reaches a preset threshold. As long as sufficient
``headroom'' is reserved to buffer packets that are in flight during the time
takes for the PAUSE to take effect, no packet will be dropped due to buffer
overflow~\cite{cisco-whitepaper,dcqcn}. 

The PFC standard defines 8 classes, called priorities~\footnote{The word priority is a
misnomer. There is no implicit ordering among priorities -- they are really just
separate classes.}. Packets in each priority are buffered separately, and PAUSE
messages carry this priority.  When a packet arrives at port $i$ of switch $S$
with priority $j$, it is enqueued in queue $j$ of port $i$. If the queue length
now exceeds the PFC threshold, a pause message (XOFF) is sent to the upstream
switch connected to port $i$. The message carries priority $j$. The upstream
switch then stops sending packets with priority $j$ to switch $S$ on port $i$ until a resume
message (XOFF) with priority $j$ is received.

\para{Deadlock:} PFC prevents buffer overflow, but it can lead to deadlocks.
Deadlock forms when paused links form a cycle
(Figure~\ref{fig:deadlock_example}). Once formed, deadlock is ``permanent'' in
the sense that it will continue to exist even if no new traffic is injected into
the loop. Deadlocks in PFC-based networks (or more generally, in credit-flow
networks) are a well-known problem. It is not merely a theoretical problem -- it
has been reported in practice~\cite{rdmaatscale}.

\para {Conditions for deadlock formation:} It is well known that Circular Buffer
Dependency (CBD) is a {\em necessary} condition for deadlock
formation~\cite{tcpbolt,hu2016deadlocks}. However, {\em
sufficient} conditions for deadlock formation in PFC networks have not yet been
fully characterized~\cite{hu2016deadlocks}. 

\para {Prior work on deadlock avoidance:} Prior work on deadlock management falls
in two categories: deadlock avoidance, or deadlock detection and resolution. Our
focus in this paper is on deadlock avoidance.  Since {\em sufficient} conditions
for deadlock formation are not well understood, deadlock avoidance schemes
focus on preventing CBD for occurring. This is done either by limiting or
modifying routing~\cite{tcpbolt} to avoid CBD, or by careful buffer
management~\cite{xxx}. 

However, these schemes fail to meet one or more of the three key challenges:
$(i)$ they cannot be deployed with existing routing, or, $(ii)$ they do not deal
with dynamic nature of data center networks, or, $(iii)$ they require excessive
switch buffers or number of priorities. 

We now describe these three challenges in more detail. See \S\ref{sec:related}
for a detailed review of prior work.

