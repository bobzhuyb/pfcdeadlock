\section{Background} \label{sec:background} \para {RDMA and RoCE:} \revisionshuihai{RDMA
technology offers high throughput, low latency and low CPU overhead, by
bypassing host networking stack. It allows Network Interface Cards (NICS) to
transfer data between pre-registered memory buffers at end hosts.  In modern
data centers, RDMA is deployed using RDMA over Converged Ethernet V2 (RoCE)
standard~\cite{rroce} }

\para {PFC:} RoCE needs a lossless fabric for optimal performance. This is
accomplished in Ethernet networks using the Priority Flow Control (PFC)
mechanism~\cite{pfc}.  Using PFC, a switch can pause an incoming link when its
ingress buffer occupancy reaches a preset threshold. As long as sufficient
``headroom'' is reserved to buffer packets that are in flight during the time
takes for the PAUSE to take effect, no packet will be dropped due to buffer
overflow~\cite{ciscowhitepaper,dcqcn}.

%ciscowhitepaper,

The PFC standard defines 8 classes, called priorities\footnote{The word priority
is a misnomer. There is no implicit ordering among priorities -- they are really
just separate classes.}. Packets in each priority are buffered separately.
PAUSE messages carry this priority.  When a packet arrives at port $i$ of switch
$S$ with priority $j$, it is enqueued in the ingress queue $j$ of port $i$. If the ingress queue
length exceeds the PFC threshold, a pause message is sent to the upstream
switch connected to port $i$. The message carries priority $j$. The upstream
switch then stops sending packets with priority $j$ to switch $S$ on port $i$
until a resume message with priority $j$ is received.

\para{Deadlock:} PFC can lead to deadlocks when paused queues form a cycle. Deadlock cannot happen if there is no Circular Buffer Dependency (CBD). Thus deadlock avoidance schemes, including this work, focus on
avoiding CBD.  We now describe the three key challenges that any
practical deadlock avoidance scheme must meet.
